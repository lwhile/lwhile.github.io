<html>

<head>
    <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>
    监控系统 | 神蛋杂谈
</title>
<link rel="shortcut icon" href="https://lwhile.github.io/favicon.ico?v=1576378575617">
<!-- <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous"> -->
<link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://lwhile.github.io/styles/main.css">
<!-- js -->
<script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>
<script src="https://lwhile.github.io/media/js/jquery.sticky-sidebar.min.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>


</head>

<body>
    <div class="main">
        <div class="header">
    <div class="nav">
        <div class="logo">
            <a href="https://lwhile.github.io">
                <img class="avatar" src="https://lwhile.github.io/images/avatar.png?v=1576378575617" alt="">
            </a>
            <div class="site-title">
                <h1>
                    神蛋杂谈
                </h1>
            </div>
        </div>
        <span class="menu-btn fa fa-align-justify"></span>
        <div class="menu-container">
            <ul>
                
                    
                            <li>
                                <a href="/" class="menu">
                                    首页
                                </a>
                            </li>
                            
                                
                    
                            <li>
                                <a href="/archives" class="menu">
                                    归档
                                </a>
                            </li>
                            
                                
                    
                            <li>
                                <a href="/tags" class="menu">
                                    标签
                                </a>
                            </li>
                            
                                
                    
                            <li>
                                <a href="/post/about" class="menu">
                                    关于
                                </a>
                            </li>
                            
                                
            </ul>
        </div>
    </div>
</div>

<script>
    $(document).ready(function() {
        $(".menu-btn").click(function() {
            $(".menu-container").slideToggle();
        });
        $(window).resize(function() {

            if (window.matchMedia('(min-width: 960px)').matches) {
                $(".menu-container").css('display', 'block')
            } else {
                $(".menu-container").css('display', 'none')
            }

        });
    });
</script>

            <div id="main-content" class="post-container main-container">
                <div id="content" class="main-container-left">
                    
    <div class="i-card">
        <b>标签：#
        监控系统</b>
    </div>
    
        
            <article class="post i-card">
                <h2 class="post-title">
                    <a href="https://lwhile.github.io/post/how-to-design-monitor-platform">
                        如何设计监控平台的告警组件
                    </a>
                </h2>
                <div class="post-info">
                    <time class="post-time">2017-11-20</time>
                    
                        <a href="https://lwhile.github.io/tag/jian-kong-xi-tong" class="post-tag i-tag
                            i-tag-">
            #监控系统
        </a>
                        
                        <a href="https://lwhile.github.io/tag/GQVNWsaTp" class="post-tag i-tag
                            i-tag-other_4">
            #计算机
        </a>
                        
                        <a href="https://lwhile.github.io/tag/5UKnY2CH9d" class="post-tag i-tag
                            i-tag-">
            #Go
        </a>
                        
                </div>
                <div class="post-article">
                    
                            <div class="post-content">
                                
                                        <div class="post-content-content">
                                            当业务发展到一定程度的时候，开发人员会开始考虑在系统中引入监控系统来对系统/业务进行监控。绝大多数监控系统都有两大核心功能，一个是工程师通过这个监控系统，能够对整个系统的运行情况一目了然，另外一个，就是当发生意外情况的时候，监控系统能将事件通知到人手上，毕竟人不可能24小时都在工作。这篇文章将要介绍的，就是第二个核心功能的承担着，告警组件。
项目背景
我们公司目前的监控系统采用的是TICK架构中的TI,即用Telegraf采集数据，Influxdb做存储。C我们用了更加流行的Grafana做了替换。至于我们为什么选择了Influxdb，可以参考这篇文章：InfluxDB与Prometheus用于监控系统上的对比
剩下K，即Kapacitor,我们最后抛弃了它，主要还是因为Kapacitor的太过于臃肿，上手和维护成本太高，很多功能我们都用不上，还不如自己开发一个。而Grafana的报警功能其实还可以，但是对于我们来说有个不大不小的缺陷，这里就不提了。于是自己心里先把实现思路过了一遍，觉得能Hold得住，就向领导请示想自己开发，接下来轮子就造起来了。
需求与设计原则
作为一个核心组件，我给自己先定了一个最基本的目标：稳定。功能多不多、炫不炫要让位给稳定性。
接下来开始思考告警组件的两个基本需求：通知，和异常事件的发现。
通知方面，邮件的方式是必不可少的。另外因为我们公司有自己的IM产品线，所以支持Webhook也是要留在考虑项里面。至于短信这些和客户的需求耦合度比较高，所以暂不考虑。
而异常事件的发现，我选择参考Kapacitor的方式，主动去DB做查询，拿到数据再做触发的判断。这种方式有个缺点，如果数据库挂了，那么数据的流入端就断了，这为系统的可用性增加了一个不确定性因素。但我们在Influxdb前面使用relay做了高可用网关，而在我们集群中relay也是高可用的，这可以抵消掉一些上面的不确定性因素。
但是反过来，如果参考Prometheus或者Open-Falcon的方式，在数据送入数据库之前，先经过告警组做判断，我们目前的监控系统就需要增加一个网关，或者将告警功能嵌入relay里面，这样一来相当于监控的数据流在进入DB前会经过两扇门，每一扇都会降低整个系统一定的吞吐量。还有一个点不得不考虑，对配置的每一次修改都需要重启程序，这势必会造成数据的丢失。为了解决这个问题，Prometheus和Open-Falcon都是将待进入DB的数据复制一份，导到告警组件这里来，而这又需要对采集组件的配合。所以基于上面基点的考虑，我就选择了主动去DB做查询的方式。
说完上面两个基本需求，还有一个定制化的需求也要考虑，我们希望能在我们的虚拟机管理平台上像主流的公有云厂商一样能够让用户配置告警的策略，所以这引入另外一个需求：对外暴露易操作的API，让前端妹子调用。
内部设计
明确了基本需求后，接下来开始内部的设计。为了理清思路，我写下了一份我（从使用者的角度）想要的配置文件（yaml格式）,来帮助我对事物进行抽象：
alert:
- name: 宿主机监控
type: influxdb
url: http://120.25.127.4:8086
db: telegraf
interval: 2s
query:
- name: cpu空闲值
sql: SELECT usage_idle FROM cpu WHERE time &amp;gt; now() - 1m
threshold: 100
op: &amp;quot;&amp;lt;=&amp;quot;
- name: 内存使用率
sql: SELECT used_percent FROM mem WHERE time &amp;gt; now() - 1m
op: &amp;quot;&amp;gt;=&amp;quot;
threshold: 50

notifier:
- name: 测试组
enable: true
type: mail 
host: smtp.163.com
port: 25
username: qq912293672@163.com
password: xxxxxx
from: qq912293672@163.com
to: [912293672@qq.com]

从配置文件上可以看到，我对告警组件抽象出了两个大的划分，一个是alert,抽象了数据的获取。一个是notifier,抽象了事件的通知。
在alert里面，我赋予了alert几个属性，其中type用来标识数据库的类型，因为我希望这个告警组件能支持多个存储后端。接下来是query，sql属性让用户自定义数据的查询方式，并且用threshold和op表示触发的阀值以及如何触发。总的来说，我采用了将多个查询实体组合成一个告警单位。这是经过思考的结果，目的是为了避免通知风暴：即很多机器很不幸都出异常的时，多个事件将聚合成一个告警，而不是发出多个邮件，而每个邮件的内容却很少。
而notifier的配置，我特意添加了type,也是为了支持多种通知方式，以及一个开关enable。
将notifier与alert分开，以及alert中包含query的设计，其实也是从Grafana和prometheus中学到的思路。在此感谢下今天的开源文化，让我等普通人有机会学到别人优秀的设计理念。
抽象得差不多后，可以考试编码了，按照分类，将代码主要分为3个模块，notify，alert,service。其中service对应我们上面的第三个需求，对外暴露API。
接口设计
开发语言上我使用的是Go，我们将会有多个query在执行，这刚好对上的Go的强项，并发。下面看下几个主要的接口：
// Executor :type Executor interface {
    Execute() ([]Result, error)
    Interval() time.Duration
    Config() Config
    Close() error
}

因为alert其实可以当做一个获取数据的执行单位，所以我在这里又抽象出了一个执行器Executor,接下来我们只需要让我们Alert实现该接口，就能被调用执行。
type Analyzer interface {
    Analyze(string, interface{}, QueryConfig) (Result, bool)
}

Analyzer接口实现对各个监控系统数据处理。
type Result interface {
    String() string
    QueryName() string}

Result接口抽象了监控系统的返回数据，屏蔽掉各个监控系统之间的数据差异。
type Notifier interface {
    Send(content string) error
    Name() string
    Type() string
    To() []string
    Enable() bool
    Config() *Config
}

通知接口
接下来我们需要实现一个调度器，实现了对上面Executor的调度和控制：
type Scheduler interface {
    Run()
    AddExecutor(executor.Executor)
    RemoveExecutor(name string)
    ExecutorExist(name string) bool
    Stop()
}

核心调度逻辑：
runFn := func(schItem *scheduleItem) {
        bf := bytes.NewBufferString(&amp;quot;&amp;quot;)
        ticker := time.NewTicker(schItem.executor.Interval())
        notiMap := make(map[string]int)
        mutex := &amp;amp;sync.RWMutex{}        for {            select {            // 定时器到期
            case &amp;lt;-ticker.C:
                results, err := schItem.executor.Execute()                if err != nil {
                    log.Error(err)                    continue
                }
                notifiers, err := adaper.ReadAllNotifier()                if err != nil {
                    log.Error(err)                    continue
                }                for _, result := range results {                    // 对通知数进行累加
                    mutex.Lock()
                    notiMap[result.QueryName()]++
                    mutex.Unlock()                    // 通知数已经超过了限制
                    log.Debugf(&amp;quot;notiMap:%+v&amp;quot;, notiMap)
                    result := result                    if notiMap[result.QueryName()] &amp;gt; notiSeqCount {                        if notiMap[result.QueryName()] == notiSeqCount+1 {                            go func(name string) {
                                time.Sleep(notiSleepDuration)
                                mutex.Lock()
                                notiMap[name] = 0
                                mutex.Unlock()
                            }(result.QueryName())
                        }                        continue
                    }                    if _, err := bf.WriteString(result.String()); err != nil {
                        log.Error(err)
                    }
                    bf.WriteString(&amp;quot;&amp;lt;br&amp;gt;&amp;quot;)
                }
                msgBody := bf.String()
                bf.Reset()                // 内容为空则跳过通知
                if msgBody == &amp;quot;&amp;quot; {                    continue
                }                // 遍历通知器将报警发送出去
                for _, notifier := range notifiers {
                    log.Debugf(&amp;quot;bool:%v&amp;quot;, notifier.Enable())                    if !notifier.Enable() {                        continue
                    }
                    notifier := notifier                    go func() {
                        err := notifier.Send(msgBody)                        if err != nil {
                            log.Errorf(&amp;quot;Send %s notify to %s fail:%s&amp;quot;, notifier.Type(), notifier.To(), err.Error())                            return
                        }
                        log.Infof(&amp;quot;Send %s notify to %s success&amp;quot;, notifier.Type(), notifier.To())
                    }()
                }            // 收到退出信号
            case &amp;lt;-schItem.closeCh:
                ticker.Stop()
                log.Infof(&amp;quot;Executor %s exit&amp;quot;, schItem.executor.Config().Name)                return
            }
        }
    }

上面的调度控制中，为了避免某个异常事件在短时间没有解决时，我实现了自己的一个控制逻辑：当同一个query的通知已经连续超过3次时，我会让它定制通知半小时。若半小时异常还继续，则再发三次通知给接受者，如此循环下去。
最后还有HTTP API的实现以及对数据的存储。这属于常规的开发逻辑，和我们这个告警组件的关系不是很大，就不一一介绍了。
总结
写这篇文章主要是总结下设计的思路，尤其是在几个核心问题上。在设计之初，除了告诉自己要保持住稳定性之外，还特别注意了如何对代码做到恰到好处的抽象，这也是最近半年看了那么多优秀开源项目的代码后的想法。老实说我这一次又对自己做得不满意，有机会我重构下整个组件。另外其实还有一个比较棘手的问题，就是如何让告警组件做到高可用（这无法通过简单部署多个服务就能实现，这样会导致通知事件的重复发送），这个问题最近正在解决，可以期待下一篇文章。
https://mp.weixin.qq.com/s/qr8WyroAWqx4D85J89RbvQ

                                        </div>
                                        
                                            <a class="btn btn-text" href="https://lwhile.github.io/post/how-to-design-monitor-platform">Read More ~</a>
                            </div>
                </div>
            </article>
            
            <article class="post i-card">
                <h2 class="post-title">
                    <a href="https://lwhile.github.io/post/influxdb-vs-prometheus">
                        InfluxDB与Prometheus用于监控系统上的对比
                    </a>
                </h2>
                <div class="post-info">
                    <time class="post-time">2017-07-20</time>
                    
                        <a href="https://lwhile.github.io/tag/influxdb" class="post-tag i-tag
                            i-tag-info">
            #influxdb
        </a>
                        
                        <a href="https://lwhile.github.io/tag/prometheus" class="post-tag i-tag
                            i-tag-other_3">
            #prometheus
        </a>
                        
                        <a href="https://lwhile.github.io/tag/jian-kong-xi-tong" class="post-tag i-tag
                            i-tag-primary">
            #监控系统
        </a>
                        
                        <a href="https://lwhile.github.io/tag/GQVNWsaTp" class="post-tag i-tag
                            i-tag-other_3">
            #计算机
        </a>
                        
                </div>
                <div class="post-article">
                    
                            <div class="post-content">
                                
                                        <div class="post-content-content">
                                            总览
首先要明白, Prometheus 提供的是一整套监控体系, 包括数据的采集,数据存储,报警, 甚至是绘图(只不过很烂,官方也推荐使用 grafana).
而 InfluxDB 只是一个时序数据库, 使用它做监控系统的话, 还需要物色数据采集器,如 telegraf, collectd 等. 甚至连报警模块, 也需要使用同为 Influxdata 公司出的 Kapacitor.从这个角度来说, Prometheus 会有运维上的优势, 因为它用起来确实很省事.
数据的采集
Prometheus 和 InfluxDB 在数据的采集上两者就选择了不同的极端, 前者只能 pull, 后者只能 push, 关于 pull 和 push 的对比,这里暂不多述.
Prometheus 把 数据的采集器叫做 exporter, xxx-exporter 运行之后会在机器上占用一个端口, 等待 Prometheus server 拉取数据.
InfluxDB 的数据采集器我们使用了 telegraf, 官方宣传插件化驱动, 其实也就那么回事, 编译的时候把很多东西的采集功能包进去压在一个二进制里面, 再用配置文件控制插件是否开启. 功能其实是蛮强大了. 也是 Go 编写, 部署算不上困难, 但用起来总会觉得多了一点什么东西.
存在感.
没错, 多了一种存在感, 对于数据采集 agent 这种东西, 存在感越低越好.
Telegraf 的默认配置文件就多达2000多行, 里面包括 push 的目的地址, 各种插件的控制目等等.相比之下, Prometheus 的 exporter  不需要任何配置文件, 不需要任何依赖, 真正的开箱即用.
但 Telgraf 有一个很吸引人的功能, 就是它能够作为一个转发代理接受来自不同程序的消息
比如可以运行一段脚本, 将结果按照一定的格式输出给 telegraf 默认的8186端口, telegraf 再写进 InfluxDB, 这样就把一个特殊的第三方业务的数据采集起来了, 不需要重启 Telegraf, 也不需要重启 InfluxDB.
如果换用 Prometheus 要怎么做呢? 我们需要引入 prometheus 的 SDK 自己编写 exporter, 而且 prometheus 会有四种指标类型,编写完之后需要去 Prometheus server 重新配置要抓取的目标, 整个下来是比 Telegraf 那一套要麻烦的.
如果你的需求很特殊, 要监控的很多第三方特殊的指标, 而对于常见的资源如硬件,数据库等监控需求不大, 那么 Telegraf + InfluxDB 会是一个不错的组合.
数据的存储
单单比较数据存储的那一部分, 它们两者之间也有很多不同.
InfluxDB 的存储引擎是基于一种叫做TSM的自研引擎, Prometheus 则是柔和了 leveldb 与 自研的存储引擎.
总的趋势都是基于时序数据进行优化, 不仅要照顾读写性能, 还要照顾删除性能与稳定性.
不过不管怎样,性能与数据的压缩对于使用者来说都不是第一要考虑的因素, 不是不重要,而是因为他们两者都做得很棒, 对于一个监控系统来说.
在使用的灵活性方面, InfluxDB 是优于 Prometheus 的,这是由于他们的产品定位决定的: InfluxDB 是一个时序数据库, Prometheus 是一个附带数据库的监控系统.举个例子, InfluxDB 有类似 Mysql 中数据库, 表的概念, 而且可以针对每个数据库设置不同的存储策略, 不得不说这些功能对于一个专门存放数据的软件系统来说还是很有吸引力的.
数据的查询
在数据查询上面, InfluxDB 的查询语言 InfluxQL 与 SQL 类似, 但是不能像 SQL 那样做强大的表与表之间的操作.
Prometheus 的查询语言也很有特点, 看起来会像 JSON , 但是通过它也可以实现各种强大的查询操作.
下面分别是 InfluxDB 和 Prometheus 查询1分钟内 CPU 使用率的语句
SELECT 100 - usage_idel FROM &amp;quot;autogen&amp;quot;.&amp;quot;cpu&amp;quot; WHERE time &amp;gt; now() - 1m and &amp;quot;cpu&amp;quot;=&#39;cpu0&#39;

100 - (node_cpu{job=&amp;quot;node&amp;quot;,mode=&amp;quot;idle&amp;quot;}[1m]) 

如果硬要在查询语言上分个高低的话,我会选择 Prometheus, 原因很简单, 我觉得它更有友好与简单
高可用与集群功能
最后还要说一下集群和高可用性这块.很遗憾他们两个现在都做得不是很好,至少从免费的角度来说:)
InfluxDB 的集群功能是商业功能, 但是有一个高可用的套件叫做 Influxdb-relay, 这个一个跑在 InfluxDB 实例前面的一个转发代理, 数据经过它的时候会被分发到各个数据库实例上. 还凑合着能用吧,不过不支持 query 操作, 如果有需要的话可以参考这个fork https://github.com/shanexu/influxdb-relay
Prometheus 到目前为止还没有看到集群功能的消息, 高可用也是仅仅通过部署多个实例来实现, 这个方案是有局限性的, 就算不考虑资源的占用, 也会让系统的架构变得复杂.
笔者一直都在等待他们能一个高可用和集群部署的功能, 尤其是 Prometheus.因为毕竟总有公司需要数据有可靠性的保证的, 尤其是面向政企客户的公司.
有一段时间笔者学了 Raft 协议的后想要自己实现 InfluxDB 的集群功能, 但总是怕自己做不好, 花的时间打了水漂, 毕竟对于笔者这样的新手来选择把精力花在打实计算机基础以及扩充自己的知识面上面会更有性价比. 但是如果有哪位读者也有实现 InfluxDB 集群功能的想法, 请告诉我, 我很愿意一起协助...
报警
如果说在前面那两个方面 InfluxDB 和 Prometheus 还各有特点的话, 那么在报警这方面 InfluxDB 简直就是被 Prometheus 按在地上摩擦.
InfluxDB 官方出了一个叫做 Kapacitor 的软件, 官方说可以用它实现报警.
但是这货明明是拿来对 InfluxDB 做数据处理的, 用在监控系统的报警功能上面真的很差.
一方面是因为效率的原因, 它的工作原理是定时得去从 InfluxDB 取数据出来进行运算来检查是否触发报警条件, 而且万一数据库挂了的话岂不是报警也失效了 ? 一方面是它的 DSL 使用起来体验真心差, 谁用谁知道 !
总结
几个月体验下来, 笔者认为对于监控系统的选择来说, Prometheus 是不二之选,市场的反应也摆在我们面前了, 这就是趋势.
另外一方面, 如果你的业务不单单是监控系统, 还需要使用到一些时序数据库的特性用来存储其他数据, 那么也别纠结了, InfluxDB就是最适合的.

                                        </div>
                                        
                                            <a class="btn btn-text" href="https://lwhile.github.io/post/influxdb-vs-prometheus">Read More ~</a>
                            </div>
                </div>
            </article>
            
            <article class="post i-card">
                <h2 class="post-title">
                    <a href="https://lwhile.github.io/post/influxdb-tcp-problem">
                        InfluxDB TCP 连接数过多问题
                    </a>
                </h2>
                <div class="post-info">
                    <time class="post-time">2017-07-17</time>
                    
                        <a href="https://lwhile.github.io/tag/influxdb" class="post-tag i-tag
                            i-tag-other_2">
            #influxdb
        </a>
                        
                        <a href="https://lwhile.github.io/tag/jian-kong-xi-tong" class="post-tag i-tag
                            i-tag-info">
            #监控系统
        </a>
                        
                        <a href="https://lwhile.github.io/tag/GQVNWsaTp" class="post-tag i-tag
                            i-tag-error">
            #计算机
        </a>
                        
                </div>
                <div class="post-article">
                    
                            <div class="post-content">
                                
                                        <div class="post-content-content">
                                            公司使用了 InfluxDB 作为监控系统的存储后端, 在一次上线后,发现与InfluxDB 使用的 8086 端口相关的 TCP 连接数竟然多大 6K+ ,有时候甚至会逼近 1w ,这个数量对于一个只是在内部使用的监控系统来说, 无论如何都是无法接受的, 于是开始一系列的排查过程. 本文记录了这个问题的主要解决过程,算是对这一次杀 bug 过程的一个总结.
问题描述
因为业务的需要, client 对 InfluxDB 做 query 时,  会经过 server 的一个 proxy , 再由 proxy 发起到 Influxdb 的 query (http) 请求. 在我们的部署架构中, proxy 与 InfluxDB 是部署在同一个 server 上的. 使用命令

netstat -apn | grep 8086

可以看到大量处于 TIME_WAIT状态的 tcp 连接
...
tcp6       0      0 127.0.0.1:8086          127.0.0.1:58874         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59454         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59084         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59023         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59602         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59027         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59383         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59053         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:58828         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:58741         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59229         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:58985         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59289         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59192         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59161         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59292         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59242         TIME_WAIT   -               
tcp6       0      0 127.0.0.1:8086          127.0.0.1:59430         TIME_WAIT   -   
...    

使用命令

netstat -apn | grep 8086 | grep TIME_WAIT | wc -l

进行计数, 会发现连接数会不断增加,  经过多次测试, 在公司环境中连接数至少都会达到 6k+. 这个问题必须要解决, 一方面是因为每条 tcp 连接都会占用内存, 另一方面系统的动态端口数也是有限的.
很明显这些连接几乎都处在 TIME_WAIT 状态,所以在继续往下走之前, 需要了解下 TIME_WAIT 这个关键字
TIME_WAIT
我们知道 一条 tcp 连接从开始到结束会经历多个状态, 换句话说, 可以把 一条 tcp 连接看成是一个 状态机. 这个状态图如下:

可以看到, 凡是主动进行关闭 tcp 连接的一方, 都会经过 TIME_WAIT 这个状态.接下来再经过 2MSL 的时间后内核再完全释放相应的文件描述符和端口. (顺便提一下, MSL 是最大分段寿命, 是一个 TCP 分段可以存在于互联网系统中的最大时间, 在 Linux 下可以用命令

cat /proc/sys/net/ipv4/tcp_fin_timeout

查看 MSL的数值)
到这个地方可以推断出, 是 8086 端口(即 InfluxDB) 主动关闭了 tcp 连接, 导致挤压了大量的处于 TIME_WAIT 状态下的连接在等待内核释放. 于是自然而然得会想到, 能不能限制 InfluxDB 能打开的最大连接数, 让它尽可能复用每一条 tcp 连接?
果不其然, 在 InfluxDB 的配置文件中, 有这么一个配置项
# The maximum number of HTTP connections that may be open at once. connections that                                                  
# would exceed this limit are dropped.  Setting this value to 0 disables the limit.
max-connection-limit = 0 

我将其该为100, 然后重启数据库.
然而并没有什么卵用, 看来还是得继续想办法.
查看 InfluxDB 源码
接下来使用 curl 查看 Influxdb 返回的 http header
HTTP/1.1 200 OK
Connection: close
Content-Type: application/json
Request-Id: 95e5b54b-6af3-11e7-8001-000000000000
X-Influxdb-Build: OSS
X-Influxdb-Version: 1.3.0rc1
Date: Mon, 17 Jul 2017 13:26:48 GMT
Transfer-Encoding: chunked

可以看到 Connection 字段被设置为 close .
因为已经确定我们用 Go 编写的用于对 InfluxDB 发起 http 请求的 proxy 已经正确复用了 tcp 连接 , 所以就感觉问题应该是处在了 InfluxDB 上, 所以接下来就开始翻开 InfluxDB 的源码查看究竟.
文章中提到的 InfluxDB 版本为 1.2 , 处理 query 请求的代码在services/httpd/handler.go 中, 函数签名为
func (h *Handler) serveQuery(w http.ResponseWriter, r *http.Request, user meta.User)

在其中发现一句代码
rw.Header().Add(&amp;quot;Connection&amp;quot;, &amp;quot;close&amp;quot;)

看到这里感觉一切豁然开朗了,  确实是 Influxdb 主动关闭的连接, 并且通知 client (也就是文中提到的 proxy )  在请求完成后也关闭连接.
为了验证这一点, 我将上面那句代码注释掉后重新编译 InfluxDB, 在 client 正确复用连接的情况下, 连接数确实可以保持在 10 以内.
现在问题就变成, InfluxDB 为何要这样设计 ?

后续
在 Github 的一个 issue 上, 我向 InfluxDB 的官方反映了这个问题, 官方也注意到了, 可能在接下来的 1.3 版本会修复这个问题, 拭目以待.
--------- 更新 ------
Influxdb 之所以会强制关闭连接, 是因为 Go 对复用的连接使用
ResponseWriter.CloseNotify()

获取通知的时候会有问题, 于是他们强制 client 在后续请求中重新建立连接而不是选择复用.不过 InfluxDB 对连接的关闭通知做了一些另外的处理, 所以上面的那句代码可以去掉.

                                        </div>
                                        
                                            <a class="btn btn-text" href="https://lwhile.github.io/post/influxdb-tcp-problem">Read More ~</a>
                            </div>
                </div>
            </article>
            
                <!-- 翻页 -->
                
                </div>
                <!--  -->
                <div class="main-container-middle"></div>
                <!--  -->
                <div id="sidebar" class="main-container-right">

                    <!-- 个人信息 -->
                    
    <div class="id_card i-card">
        <div class="id_card-avatar" style="background-image: url(https://lwhile.github.io/images/avatar.png?v=1576378575617)">
        </div>
        <h1 class="id_card-title">
            神蛋杂谈
        </h1>
        <h2 class="id_card-description">
            
        </h2>
        <!--  -->
        <div class="id_card-sns">
            <!-- github -->
            
                    <!-- twitter -->
                    
                            <!-- weibo -->
                            
                                    <!-- facebook -->
                                    

        </div>
    </div>
    

                        <!-- 公告栏 -->
                        

                </div>
            </div>



            <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://lwhile.github.io/atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()
</script>

    </div>
    <script>
        $('#sidebar').stickySidebar({
            topSpacing: 80,
            // bottomSpacing: 60
        });
    </script>
</body>

</html>